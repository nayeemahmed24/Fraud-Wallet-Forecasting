{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49983250-1e30-4b16-8c4a-0c18ecd25753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions: 205705\n",
      "Wallets: 387\n",
      "                                      address           timeStamp  \\\n",
      "0  0x0000000dc3d9e17e3449e59bb75cb4005ee8aa7f 2023-02-22 23:59:59   \n",
      "1  0x0000000dc3d9e17e3449e59bb75cb4005ee8aa7f 2023-02-23 00:05:47   \n",
      "2  0x0000000dc3d9e17e3449e59bb75cb4005ee8aa7f 2023-02-23 03:09:35   \n",
      "\n",
      "                                         from  \\\n",
      "0  0x0000000dc3d9e17e3449e59bb75cb4005ee8aa7f   \n",
      "1  0x0000000dc3d9e17e3449e59bb75cb4005ee8aa7f   \n",
      "2  0x0000000dc3d9e17e3449e59bb75cb4005ee8aa7f   \n",
      "\n",
      "                                           to  value     gas     gasPrice  \\\n",
      "0  0xbe9895146f7af43049ca1c1ae358b0541ea49704    0.0  364852  35343810889   \n",
      "1  0xbe9895146f7af43049ca1c1ae358b0541ea49704    0.0  149122  35343810889   \n",
      "2  0x5283d291dbcf85356a21ba090e6db59121208b44    0.0  299884  37347507096   \n",
      "\n",
      "   gasUsed                                       functionName  isError  \\\n",
      "0    90306  permit(address owner, address spender, uint256...      0.0   \n",
      "1    69093  transferFrom(address _from, address _to, uint2...      0.0   \n",
      "2    74971  permit(address owner, address spender, uint256...      0.0   \n",
      "\n",
      "   txreceipt_status  label               source_file  \n",
      "0               1.0      1  normal_transactions.json  \n",
      "1               1.0      1  normal_transactions.json  \n",
      "2               1.0      1  normal_transactions.json  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load mini dataset\n",
    "tx_df = pd.read_parquet(\"mini_transactions.parquet\")\n",
    "\n",
    "# Basic hygiene\n",
    "# Keep only columns we use\n",
    "use_cols = [\n",
    "    \"address\",\"timeStamp\",\"from\",\"to\",\"value\",\"gas\",\"gasPrice\",\"gasUsed\",\n",
    "    \"functionName\",\"isError\",\"txreceipt_status\",\"label\",\"source_file\"\n",
    "]\n",
    "tx_df = tx_df[[c for c in use_cols if c in tx_df.columns]].copy()\n",
    "\n",
    "# Standardize address case\n",
    "tx_df[\"address\"] = tx_df[\"address\"].str.lower()\n",
    "tx_df[\"from\"]    = tx_df[\"from\"].str.lower()\n",
    "tx_df[\"to\"]      = tx_df[\"to\"].str.lower()\n",
    "\n",
    "# Timestamps\n",
    "# Real-CATS often stores UNIX seconds as strings—handle both int & str safely\n",
    "tx_df[\"timeStamp\"] = pd.to_numeric(tx_df[\"timeStamp\"], errors=\"coerce\")\n",
    "tx_df = tx_df.dropna(subset=[\"timeStamp\"])\n",
    "tx_df[\"timeStamp\"] = pd.to_datetime(tx_df[\"timeStamp\"], unit=\"s\")\n",
    "\n",
    "# Numerics (Ethereum units are often strings in wei)\n",
    "for num_col in [\"value\",\"gas\",\"gasPrice\",\"gasUsed\",\"isError\",\"txreceipt_status\"]:\n",
    "    if num_col in tx_df.columns:\n",
    "        tx_df[num_col] = pd.to_numeric(tx_df[num_col], errors=\"coerce\")\n",
    "\n",
    "# Keep only rows with a functionName (you asked to filter these earlier)\n",
    "if \"functionName\" in tx_df.columns:\n",
    "    tx_df[\"functionName\"] = tx_df[\"functionName\"].astype(str).str.strip()\n",
    "    tx_df = tx_df[tx_df[\"functionName\"] != \"\"]\n",
    "    tx_df = tx_df.dropna(subset=[\"functionName\"])\n",
    "\n",
    "# Sort by wallet and time\n",
    "tx_df = tx_df.sort_values([\"address\",\"timeStamp\"]).reset_index(drop=True)\n",
    "\n",
    "# Sanity checks\n",
    "print(\"Transactions:\", len(tx_df))\n",
    "print(\"Wallets:\", tx_df[\"address\"].nunique())\n",
    "print(tx_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28135c1d-a3fc-4087-9c71-722f7573e5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-tx feature count: 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dir_out</th>\n",
       "      <th>value_eth_log1p</th>\n",
       "      <th>gas_log1p</th>\n",
       "      <th>gasPrice_log1p</th>\n",
       "      <th>gasUsed_log1p</th>\n",
       "      <th>err_flag</th>\n",
       "      <th>tx_gap_s_log1p</th>\n",
       "      <th>is_erc20</th>\n",
       "      <th>fn_0xfb0f3ee1()</th>\n",
       "      <th>fn_None</th>\n",
       "      <th>...</th>\n",
       "      <th>fn_swapExactETHForTokens(uint256 amountOutMin, address[] path, address to, uint256 deadline)</th>\n",
       "      <th>fn_swapExactETHForTokensSupportingFeeOnTransferTokens(uint256 amountOutMin, address[] path, address to, uint256 deadline)</th>\n",
       "      <th>fn_swapExactTokensForETHSupportingFeeOnTransferTokens(uint256 amountIn, uint256 amountOutMin, address[] path, address to, uint256 deadline)</th>\n",
       "      <th>fn_transfer(address _to, uint256 _value)</th>\n",
       "      <th>fn_transfer(address token, address from, address to, uint256 share)</th>\n",
       "      <th>fn_transferFrom(address _from, address _to, uint256 _value)</th>\n",
       "      <th>fn_withdraw(uint256 amount)</th>\n",
       "      <th>address</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.807250</td>\n",
       "      <td>24.288389</td>\n",
       "      <td>11.410970</td>\n",
       "      <td>0</td>\n",
       "      <td>4.430817</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0x0000000dc3d9e17e3449e59bb75cb4005ee8aa7f</td>\n",
       "      <td>2023-02-22 23:59:59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.912527</td>\n",
       "      <td>24.288389</td>\n",
       "      <td>11.143223</td>\n",
       "      <td>0</td>\n",
       "      <td>5.855072</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0x0000000dc3d9e17e3449e59bb75cb4005ee8aa7f</td>\n",
       "      <td>2023-02-23 00:05:47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.611154</td>\n",
       "      <td>24.343532</td>\n",
       "      <td>11.224870</td>\n",
       "      <td>0</td>\n",
       "      <td>9.308283</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0x0000000dc3d9e17e3449e59bb75cb4005ee8aa7f</td>\n",
       "      <td>2023-02-23 03:09:35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dir_out  value_eth_log1p  gas_log1p  gasPrice_log1p  gasUsed_log1p  \\\n",
       "0        1              0.0  12.807250       24.288389      11.410970   \n",
       "1        1              0.0  11.912527       24.288389      11.143223   \n",
       "2        1              0.0  12.611154       24.343532      11.224870   \n",
       "\n",
       "   err_flag  tx_gap_s_log1p  is_erc20  fn_0xfb0f3ee1()  fn_None  ...  \\\n",
       "0         0        4.430817         0            False    False  ...   \n",
       "1         0        5.855072         0            False    False  ...   \n",
       "2         0        9.308283         0            False    False  ...   \n",
       "\n",
       "   fn_swapExactETHForTokens(uint256 amountOutMin, address[] path, address to, uint256 deadline)  \\\n",
       "0                                              False                                              \n",
       "1                                              False                                              \n",
       "2                                              False                                              \n",
       "\n",
       "   fn_swapExactETHForTokensSupportingFeeOnTransferTokens(uint256 amountOutMin, address[] path, address to, uint256 deadline)  \\\n",
       "0                                              False                                                                           \n",
       "1                                              False                                                                           \n",
       "2                                              False                                                                           \n",
       "\n",
       "   fn_swapExactTokensForETHSupportingFeeOnTransferTokens(uint256 amountIn, uint256 amountOutMin, address[] path, address to, uint256 deadline)  \\\n",
       "0                                              False                                                                                             \n",
       "1                                              False                                                                                             \n",
       "2                                              False                                                                                             \n",
       "\n",
       "   fn_transfer(address _to, uint256 _value)  \\\n",
       "0                                     False   \n",
       "1                                     False   \n",
       "2                                     False   \n",
       "\n",
       "   fn_transfer(address token, address from, address to, uint256 share)  \\\n",
       "0                                              False                     \n",
       "1                                              False                     \n",
       "2                                              False                     \n",
       "\n",
       "   fn_transferFrom(address _from, address _to, uint256 _value)  \\\n",
       "0                                              False             \n",
       "1                                               True             \n",
       "2                                              False             \n",
       "\n",
       "   fn_withdraw(uint256 amount)                                     address  \\\n",
       "0                        False  0x0000000dc3d9e17e3449e59bb75cb4005ee8aa7f   \n",
       "1                        False  0x0000000dc3d9e17e3449e59bb75cb4005ee8aa7f   \n",
       "2                        False  0x0000000dc3d9e17e3449e59bb75cb4005ee8aa7f   \n",
       "\n",
       "            timeStamp  label  \n",
       "0 2023-02-22 23:59:59      1  \n",
       "1 2023-02-23 00:05:47      1  \n",
       "2 2023-02-23 03:09:35      1  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Direction: whether wallet is sender in this row\n",
    "tx_df[\"dir_out\"] = (tx_df[\"from\"] == tx_df[\"address\"]).astype(int)\n",
    "\n",
    "# Ether value in wei -> ETH -> log1p\n",
    "tx_df[\"value_eth\"] = tx_df[\"value\"] / 1e18\n",
    "tx_df[\"value_eth_log1p\"] = np.log1p(tx_df[\"value_eth\"].clip(lower=0))\n",
    "\n",
    "# Gas-like features\n",
    "for col in [\"gas\",\"gasPrice\",\"gasUsed\"]:\n",
    "    if col in tx_df.columns:\n",
    "        tx_df[f\"{col}_log1p\"] = np.log1p(tx_df[col].fillna(0).clip(lower=0))\n",
    "    else:\n",
    "        tx_df[f\"{col}_log1p\"] = 0.0\n",
    "\n",
    "# Error flags\n",
    "tx_df[\"err_flag\"] = tx_df[\"isError\"].fillna(0).astype(int).clip(0,1)\n",
    "\n",
    "# Time gap per wallet\n",
    "tx_df[\"prev_time\"] = tx_df.groupby(\"address\")[\"timeStamp\"].shift(1)\n",
    "tx_df[\"tx_gap_s\"]  = (tx_df[\"timeStamp\"] - tx_df[\"prev_time\"]).dt.total_seconds()\n",
    "tx_df[\"tx_gap_s\"]  = tx_df[\"tx_gap_s\"].fillna(tx_df[\"tx_gap_s\"].median())  # fill first gap\n",
    "tx_df[\"tx_gap_s_log1p\"] = np.log1p(tx_df[\"tx_gap_s\"].clip(lower=0))\n",
    "\n",
    "# ERC20 vs normal (depends on how you named it)\n",
    "tx_df[\"is_erc20\"] = tx_df[\"source_file\"].astype(str).str.contains(\"erc20\", case=False, na=False).astype(int)\n",
    "\n",
    "# FunctionName one-hot (top N)\n",
    "TOP_N_FUNCS = 20\n",
    "top_funcs = tx_df[\"functionName\"].value_counts().nlargest(TOP_N_FUNCS).index.tolist()\n",
    "tx_df[\"functionName_squashed\"] = np.where(tx_df[\"functionName\"].isin(top_funcs), tx_df[\"functionName\"], \"OTHER\")\n",
    "\n",
    "# Build one-hot columns\n",
    "func_dummies = pd.get_dummies(tx_df[\"functionName_squashed\"], prefix=\"fn\")\n",
    "tx_df = pd.concat([tx_df, func_dummies], axis=1)\n",
    "\n",
    "# Define final per-transaction feature columns\n",
    "tx_features = [\n",
    "    \"dir_out\",\n",
    "    \"value_eth_log1p\",\"gas_log1p\",\"gasPrice_log1p\",\"gasUsed_log1p\",\n",
    "    \"err_flag\",\"tx_gap_s_log1p\",\"is_erc20\"\n",
    "] + sorted([c for c in tx_df.columns if c.startswith(\"fn_\")])\n",
    "\n",
    "print(\"Per-tx feature count:\", len(tx_features))\n",
    "tx_df[tx_features + [\"address\",\"timeStamp\",\"label\"]].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984dfd72-35c8-47b8-986c-81ac985e83d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((309, 50, 29), (309,), (78, 50, 29), (78,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Build a list of wallets with labels\n",
    "wallet_labels = tx_df[[\"address\",\"label\"]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Train/test split by wallet (to avoid leakage)\n",
    "train_wallets, test_wallets = train_test_split(\n",
    "    wallet_labels, test_size=0.2, stratify=wallet_labels[\"label\"], random_state=42\n",
    ")\n",
    "train_set = set(train_wallets[\"address\"])\n",
    "test_set  = set(test_wallets[\"address\"])\n",
    "\n",
    "SEQ_LEN = 50\n",
    "\n",
    "def wallet_to_matrix(df_wallet, features, seq_len=SEQ_LEN):\n",
    "    \"\"\"\n",
    "    Given a single wallet's df (time-ordered), return a (seq_len, d) matrix\n",
    "    using the most recent seq_len transactions, padding at the front if necessary.\n",
    "    \"\"\"\n",
    "    X = df_wallet[features].to_numpy(dtype=np.float32)\n",
    "    if len(X) >= seq_len:\n",
    "        X = X[-seq_len:]  # last seq_len\n",
    "    else:\n",
    "        pad = np.zeros((seq_len - len(X), X.shape[1]), dtype=np.float32)\n",
    "        X = np.vstack([pad, X])\n",
    "    return X\n",
    "\n",
    "# Build raw (unscaled) sequences for train & test\n",
    "def build_sequences(frame, wallet_list):\n",
    "    X_list, y_list = [], []\n",
    "    for addr in wallet_list:\n",
    "        w = frame[frame[\"address\"] == addr].sort_values(\"timeStamp\")\n",
    "        if w.empty:\n",
    "            continue\n",
    "        mat = wallet_to_matrix(w, tx_features, SEQ_LEN)\n",
    "        label = int(w[\"label\"].iloc[0])\n",
    "        X_list.append(mat)\n",
    "        y_list.append(label)\n",
    "    X = np.stack(X_list, axis=0)  # (N, T, D)\n",
    "    y = np.array(y_list, dtype=np.int64)\n",
    "    return X, y\n",
    "\n",
    "train_df = tx_df[tx_df[\"address\"].isin(train_set)]\n",
    "test_df  = tx_df[tx_df[\"address\"].isin(test_set)]\n",
    "\n",
    "# Fit scaler on TRAIN transactions only (flattened)\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "scaler.fit(train_df[tx_features].to_numpy(dtype=np.float32))\n",
    "\n",
    "# Apply scaler\n",
    "train_df_scaled = train_df.copy()\n",
    "test_df_scaled  = test_df.copy()\n",
    "train_df_scaled[tx_features] = scaler.transform(train_df[tx_features].to_numpy(dtype=np.float32))\n",
    "test_df_scaled[tx_features]  = scaler.transform(test_df[tx_features].to_numpy(dtype=np.float32))\n",
    "\n",
    "# Sequences\n",
    "X_train, y_train = build_sequences(train_df_scaled, list(train_set))\n",
    "X_test,  y_test  = build_sequences(test_df_scaled,  list(test_set))\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f4565c8-3b61-427b-a5e1-6e2c589261b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.6933 | ROC-AUC=0.7296 | PR-AUC=0.7247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | train_loss=0.6826 | ROC-AUC=0.7561 | PR-AUC=0.7643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | train_loss=0.6626 | ROC-AUC=0.7508 | PR-AUC=0.7706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | train_loss=0.6240 | ROC-AUC=0.7535 | PR-AUC=0.7685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | train_loss=0.5986 | ROC-AUC=0.7668 | PR-AUC=0.7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | train_loss=0.5676 | ROC-AUC=0.7774 | PR-AUC=0.7509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | train_loss=0.5281 | ROC-AUC=0.7854 | PR-AUC=0.7514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | train_loss=0.4767 | ROC-AUC=0.7748 | PR-AUC=0.7360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | train_loss=0.4189 | ROC-AUC=0.7774 | PR-AUC=0.7170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train_loss=0.4518 | ROC-AUC=0.7635 | PR-AUC=0.7071\n",
      "Best PR-AUC: 0.7706373516646063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class WalletSeqDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)  # (N,T,D)\n",
    "        self.y = torch.from_numpy(y)  # (N,)\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = WalletSeqDataset(X_train, y_train)\n",
    "test_ds  = WalletSeqDataset(X_test,  y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, drop_last=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False, drop_last=False)\n",
    "\n",
    "# Simple LSTM classifier\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, d_in, d_hidden=64, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=d_in, hidden_size=d_hidden, num_layers=num_layers,\n",
    "            batch_first=True, dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_hidden, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):              # x: (B, T, D)\n",
    "        out, _ = self.lstm(x)          # out: (B, T, H)\n",
    "        last = out[:, -1, :]           # last step\n",
    "        logits = self.head(last)       # (B, 1)\n",
    "        return logits.squeeze(-1)      # (B,)\n",
    "\n",
    "d_in = X_train.shape[2]\n",
    "model = LSTMClassifier(d_in=d_in, d_hidden=96, num_layers=2, dropout=0.2).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_logits, all_y = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device).float()\n",
    "            logits = model(xb)\n",
    "            all_logits.append(logits.detach().cpu().numpy())\n",
    "            all_y.append(yb.cpu().numpy())\n",
    "    y_true  = np.concatenate(all_y)\n",
    "    y_score = 1/(1+np.exp(-np.concatenate(all_logits)))  # sigmoid\n",
    "    try:\n",
    "        roc = roc_auc_score(y_true, y_score)\n",
    "    except ValueError:\n",
    "        roc = np.nan\n",
    "    try:\n",
    "        pr  = average_precision_score(y_true, y_score)\n",
    "    except ValueError:\n",
    "        pr = np.nan\n",
    "    return roc, pr, y_true, y_score\n",
    "\n",
    "best_pr = -1\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\", leave=False):\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running += loss.item() * xb.size(0)\n",
    "\n",
    "    train_loss = running / len(train_ds)\n",
    "    roc, pr, y_true, y_score = evaluate(model, test_loader)\n",
    "    print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | ROC-AUC={roc:.4f} | PR-AUC={pr:.4f}\")\n",
    "    if pr > best_pr:\n",
    "        best_pr = pr\n",
    "        torch.save(model.state_dict(), \"best_lstm_wallet.pt\")\n",
    "\n",
    "print(\"Best PR-AUC:\", best_pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f30467e-bd7c-41fc-972d-6b35fc0bf476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.6933 | ROC-AUC=0.7296 | PR-AUC=0.7247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | train_loss=0.6826 | ROC-AUC=0.7561 | PR-AUC=0.7643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | train_loss=0.6626 | ROC-AUC=0.7508 | PR-AUC=0.7706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | train_loss=0.6240 | ROC-AUC=0.7535 | PR-AUC=0.7685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | train_loss=0.5986 | ROC-AUC=0.7668 | PR-AUC=0.7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | train_loss=0.5676 | ROC-AUC=0.7774 | PR-AUC=0.7509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | train_loss=0.5281 | ROC-AUC=0.7854 | PR-AUC=0.7514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | train_loss=0.4767 | ROC-AUC=0.7748 | PR-AUC=0.7360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | train_loss=0.4189 | ROC-AUC=0.7774 | PR-AUC=0.7170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train_loss=0.4518 | ROC-AUC=0.7635 | PR-AUC=0.7071\n",
      "Best PR-AUC: 0.7706373516646063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class WalletSeqDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)  # (N,T,D)\n",
    "        self.y = torch.from_numpy(y)  # (N,)\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = WalletSeqDataset(X_train, y_train)\n",
    "test_ds  = WalletSeqDataset(X_test,  y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, drop_last=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False, drop_last=False)\n",
    "\n",
    "# Simple LSTM classifier\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, d_in, d_hidden=64, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=d_in, hidden_size=d_hidden, num_layers=num_layers,\n",
    "            batch_first=True, dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_hidden, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):              # x: (B, T, D)\n",
    "        out, _ = self.lstm(x)          # out: (B, T, H)\n",
    "        last = out[:, -1, :]           # last step\n",
    "        logits = self.head(last)       # (B, 1)\n",
    "        return logits.squeeze(-1)      # (B,)\n",
    "\n",
    "d_in = X_train.shape[2]\n",
    "model = LSTMClassifier(d_in=d_in, d_hidden=96, num_layers=2, dropout=0.2).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_logits, all_y = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device).float()\n",
    "            logits = model(xb)\n",
    "            all_logits.append(logits.detach().cpu().numpy())\n",
    "            all_y.append(yb.cpu().numpy())\n",
    "    y_true  = np.concatenate(all_y)\n",
    "    y_score = 1/(1+np.exp(-np.concatenate(all_logits)))  # sigmoid\n",
    "    try:\n",
    "        roc = roc_auc_score(y_true, y_score)\n",
    "    except ValueError:\n",
    "        roc = np.nan\n",
    "    try:\n",
    "        pr  = average_precision_score(y_true, y_score)\n",
    "    except ValueError:\n",
    "        pr = np.nan\n",
    "    return roc, pr, y_true, y_score\n",
    "\n",
    "best_pr = -1\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\", leave=False):\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running += loss.item() * xb.size(0)\n",
    "\n",
    "    train_loss = running / len(train_ds)\n",
    "    roc, pr, y_true, y_score = evaluate(model, test_loader)\n",
    "    print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | ROC-AUC={roc:.4f} | PR-AUC={pr:.4f}\")\n",
    "    if pr > best_pr:\n",
    "        best_pr = pr\n",
    "        torch.save(model.state_dict(), \"best_lstm_wallet.pt\")\n",
    "\n",
    "print(\"Best PR-AUC:\", best_pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d13fc8-071d-4173-93c2-502afbd610ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wallet_proba(wallet_df_raw):\n",
    "    \"\"\"\n",
    "    wallet_df_raw: transactions for ONE wallet (original columns).\n",
    "    Returns fraud probability using the trained LSTM.\n",
    "    \"\"\"\n",
    "    # Build the same features and order as training\n",
    "    w = wallet_df_raw.sort_values(\"timeStamp\").copy()\n",
    "\n",
    "    # Recompute derived columns in the SAME WAY\n",
    "    w[\"dir_out\"] = (w[\"from\"].str.lower() == w[\"address\"].str.lower()).astype(int)\n",
    "    w[\"value_eth\"] = pd.to_numeric(w[\"value\"], errors=\"coerce\") / 1e18\n",
    "    w[\"value_eth_log1p\"] = np.log1p(w[\"value_eth\"].clip(lower=0))\n",
    "\n",
    "    for col in [\"gas\",\"gasPrice\",\"gasUsed\"]:\n",
    "        if col in w.columns:\n",
    "            w[f\"{col}_log1p\"] = np.log1p(pd.to_numeric(w[col], errors=\"coerce\").fillna(0).clip(lower=0))\n",
    "        else:\n",
    "            w[f\"{col}_log1p\"] = 0.0\n",
    "\n",
    "    w[\"isError\"] = pd.to_numeric(w.get(\"isError\", 0), errors=\"coerce\").fillna(0)\n",
    "    w[\"err_flag\"] = w[\"isError\"].astype(int).clip(0,1)\n",
    "    w[\"prev_time\"] = w.groupby(\"address\")[\"timeStamp\"].shift(1)\n",
    "    w[\"tx_gap_s\"] = (w[\"timeStamp\"] - w[\"prev_time\"]).dt.total_seconds()\n",
    "    w[\"tx_gap_s\"] = w[\"tx_gap_s\"].fillna(w[\"tx_gap_s\"].median() if w[\"tx_gap_s\"].notna().any() else 0)\n",
    "    w[\"tx_gap_s_log1p\"] = np.log1p(w[\"tx_gap_s\"].clip(lower=0))\n",
    "    w[\"is_erc20\"] = w[\"source_file\"].astype(str).str.contains(\"erc20\", case=False, na=False).astype(int)\n",
    "    w[\"functionName\"] = w[\"functionName\"].astype(str).str.strip()\n",
    "    w[\"functionName_squashed\"] = np.where(w[\"functionName\"].isin(top_funcs), w[\"functionName\"], \"OTHER\")\n",
    "\n",
    "    # Make all fn_ columns present (align with train set)\n",
    "    for fn in [\"fn_\" + f for f in (top_funcs + [\"OTHER\"])]:\n",
    "        if fn not in w.columns:\n",
    "            w[fn] = 0\n",
    "    fn_cols = sorted([c for c in w.columns if c.startswith(\"fn_\")])\n",
    "\n",
    "    # Build matrix\n",
    "    feats = [\n",
    "        \"dir_out\",\"value_eth_log1p\",\"gas_log1p\",\"gasPrice_log1p\",\"gasUsed_log1p\",\n",
    "        \"err_flag\",\"tx_gap_s_log1p\",\"is_erc20\"\n",
    "    ] + fn_cols\n",
    "    w_feats = w[feats].fillna(0).to_numpy(dtype=np.float32)\n",
    "\n",
    "    # Scale using the fitted scaler\n",
    "    w_feats = scaler.transform(w[feats].fillna(0).to_numpy(dtype=np.float32))\n",
    "\n",
    "    # Pad/trim to SEQ_LEN\n",
    "    if len(w_feats) >= SEQ_LEN:\n",
    "        w_feats = w_feats[-SEQ_LEN:]\n",
    "    else:\n",
    "        pad = np.zeros((SEQ_LEN - len(w_feats), w_feats.shape[1]), dtype=np.float32)\n",
    "        w_feats = np.vstack([pad, w_feats])\n",
    "\n",
    "    # To tensor & predict\n",
    "    model2 = LSTMClassifier(d_in=w_feats.shape[1], d_hidden=96, num_layers=2, dropout=0.2)\n",
    "    model2.load_state_dict(torch.load(\"best_lstm_wallet.pt\", map_location=\"cpu\"))\n",
    "    model2.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model2(torch.from_numpy(w_feats[None, ...]).float())\n",
    "        prob = torch.sigmoid(logits).item()\n",
    "    return prob\n",
    "\n",
    "# Example:\n",
    "# prob = predict_wallet_proba(tx_df[tx_df[\"address\"] == \"0x232e2fd91c88f8e2a06acdaa0ed199516ba31efa\"])\n",
    "# print(\"Fraud probability:\", prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fb7a96f-7a1c-4685-980e-08698e007152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics on test set:\n",
      "Accuracy: 0.7051\n",
      "Precision: 0.8000\n",
      "Recall: 0.4571\n",
      "F1: 0.5818\n",
      "AUC: 0.7635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def evaluate_model_metrics(model, loader, device):\n",
    "    model.eval()\n",
    "    y_true, y_pred_prob, y_pred_bin = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X = X.to(device)\n",
    "            outputs = model(X).squeeze().cpu().numpy()\n",
    "            \n",
    "            preds_bin = (outputs > 0.5).astype(int)\n",
    "            \n",
    "            y_pred_prob.extend(outputs.tolist())\n",
    "            y_pred_bin.extend(preds_bin.tolist())\n",
    "            y_true.extend(y.numpy().tolist())\n",
    "    \n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred_bin),\n",
    "        \"Precision\": precision_score(y_true, y_pred_bin),\n",
    "        \"Recall\": recall_score(y_true, y_pred_bin),\n",
    "        \"F1\": f1_score(y_true, y_pred_bin),\n",
    "        \"AUC\": roc_auc_score(y_true, y_pred_prob)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Example usage\n",
    "metrics = evaluate_model_metrics(model, test_loader, device)\n",
    "print(\"Evaluation metrics on test set:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe114b35-0e87-4e21-85c8-1758bd35e4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wallet 00 | true=1 | pred=0 | prob=0.0594\n",
      "Wallet 01 | true=0 | pred=0 | prob=0.1892\n",
      "Wallet 02 | true=1 | pred=0 | prob=0.2477\n",
      "Wallet 03 | true=0 | pred=0 | prob=0.1034\n",
      "Wallet 04 | true=1 | pred=1 | prob=0.9522\n",
      "Wallet 05 | true=0 | pred=0 | prob=0.3447\n",
      "Wallet 06 | true=0 | pred=0 | prob=0.2987\n",
      "Wallet 07 | true=0 | pred=0 | prob=0.2399\n",
      "Wallet 08 | true=1 | pred=0 | prob=0.2904\n",
      "Wallet 09 | true=0 | pred=1 | prob=0.6039\n",
      "Wallet 10 | true=1 | pred=0 | prob=0.1062\n",
      "Wallet 11 | true=1 | pred=0 | prob=0.1000\n",
      "Wallet 12 | true=1 | pred=0 | prob=0.2075\n",
      "Wallet 13 | true=0 | pred=0 | prob=0.4096\n",
      "Wallet 14 | true=0 | pred=0 | prob=0.3050\n",
      "Wallet 15 | true=1 | pred=1 | prob=0.9821\n",
      "Wallet 16 | true=1 | pred=1 | prob=0.9219\n",
      "Wallet 17 | true=0 | pred=0 | prob=0.1130\n",
      "Wallet 18 | true=0 | pred=1 | prob=0.9644\n",
      "Wallet 19 | true=1 | pred=1 | prob=0.7984\n",
      "Wallet 20 | true=1 | pred=0 | prob=0.2963\n",
      "Wallet 21 | true=0 | pred=0 | prob=0.2648\n",
      "Wallet 22 | true=0 | pred=0 | prob=0.0632\n",
      "Wallet 23 | true=0 | pred=0 | prob=0.1558\n",
      "Wallet 24 | true=0 | pred=0 | prob=0.0414\n",
      "Wallet 25 | true=1 | pred=1 | prob=0.9263\n",
      "Wallet 26 | true=1 | pred=0 | prob=0.2424\n",
      "Wallet 27 | true=1 | pred=0 | prob=0.1282\n",
      "Wallet 28 | true=0 | pred=0 | prob=0.0355\n",
      "Wallet 29 | true=0 | pred=0 | prob=0.1279\n",
      "Wallet 30 | true=0 | pred=0 | prob=0.3952\n",
      "Wallet 31 | true=1 | pred=1 | prob=0.5447\n",
      "Wallet 32 | true=0 | pred=0 | prob=0.2495\n",
      "Wallet 33 | true=1 | pred=0 | prob=0.4447\n",
      "Wallet 34 | true=1 | pred=0 | prob=0.2980\n",
      "Wallet 35 | true=0 | pred=0 | prob=0.3120\n",
      "Wallet 36 | true=0 | pred=1 | prob=0.9258\n",
      "Wallet 37 | true=0 | pred=0 | prob=0.1751\n",
      "Wallet 38 | true=1 | pred=1 | prob=0.8261\n",
      "Wallet 39 | true=1 | pred=1 | prob=0.8801\n",
      "Wallet 40 | true=1 | pred=1 | prob=0.9116\n",
      "Wallet 41 | true=1 | pred=1 | prob=0.8058\n",
      "Wallet 42 | true=0 | pred=0 | prob=0.0800\n",
      "Wallet 43 | true=0 | pred=0 | prob=0.2256\n",
      "Wallet 44 | true=0 | pred=0 | prob=0.0812\n",
      "Wallet 45 | true=0 | pred=1 | prob=0.9390\n",
      "Wallet 46 | true=0 | pred=0 | prob=0.0523\n",
      "Wallet 47 | true=1 | pred=1 | prob=0.9802\n",
      "Wallet 48 | true=0 | pred=1 | prob=0.5176\n",
      "Wallet 49 | true=0 | pred=0 | prob=0.0553\n",
      "\n",
      "Correct predictions (first 30): 34/count\n",
      "Accuracy (first 30): 68.00%\n"
     ]
    }
   ],
   "source": [
    "count = 50\n",
    "\n",
    "\n",
    "def predict_wallet_scores(model, loader, device):\n",
    "    model.eval()\n",
    "    all_probs, all_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X = X.to(device)\n",
    "            logits = model(X).squeeze().cpu().numpy()\n",
    "            probs  = 1 / (1 + np.exp(-logits))\n",
    "            all_probs.extend(probs.tolist())\n",
    "            all_true.extend(y.numpy().tolist())\n",
    "    return np.array(all_true), np.array(all_probs)\n",
    "\n",
    "y_true, y_forecast = predict_wallet_scores(model, test_loader, device)\n",
    "\n",
    "# Example: show first 10 forecast probs\n",
    "def predict_wallet_scores(model, loader, device):\n",
    "    model.eval()\n",
    "    all_probs, all_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X = X.to(device)\n",
    "            logits = model(X).squeeze().cpu().numpy()\n",
    "            probs  = 1 / (1 + np.exp(-logits))\n",
    "            all_probs.extend(probs.tolist())\n",
    "            all_true.extend(y.numpy().tolist())\n",
    "    return np.array(all_true), np.array(all_probs)\n",
    "\n",
    "y_true, y_forecast = predict_wallet_scores(model, test_loader, device)\n",
    "\n",
    "# Convert forecast probs -> predicted labels\n",
    "threshold = 0.5\n",
    "y_pred = (y_forecast >= threshold).astype(int)\n",
    "\n",
    "# Show first 30 wallets with ground truth, predicted label, and probability\n",
    "for i in range(count):\n",
    "    print(f\"Wallet {i:02d} | true={y_true[i]} | pred={y_pred[i]} | prob={y_forecast[i]:.4f}\")\n",
    "\n",
    "# Compute percentage correct for these 30\n",
    "correct = (y_pred[:count] == y_true[:count]).sum()\n",
    "accuracy_percent = 100.0 * correct / count\n",
    "print(f\"\\nCorrect predictions (first 30): {correct}/count\")\n",
    "print(f\"Accuracy (first 30): {accuracy_percent:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87e9bead-f10a-44ba-9972-cfc19ab134da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Example: your y_true and y_forecast arrays\n",
    "# y_true = np.array([...])         # ground truth labels\n",
    "# y_forecast = np.array([...])     # model probabilities\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred = (y_forecast >= threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c83c53e-100b-419b-90e1-7d283ff1b854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6923\n",
      "Precision: 0.7391\n",
      "Recall   : 0.4857\n",
      "F1 Score : 0.5862\n"
     ]
    }
   ],
   "source": [
    "accuracy  = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall    = recall_score(y_true, y_pred)\n",
    "f1        = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "824ef74e-3cdb-4249-bff7-f24dcc7f80c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6923\n",
      "Precision: 0.7391\n",
      "Recall   : 0.4857\n",
      "F1 Score : 0.5862\n",
      "AUC      : 0.7635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Get true labels and forecast probabilities\n",
    "y_true, y_forecast = predict_wallet_scores(model, test_loader, device)\n",
    "\n",
    "# Convert probabilities to binary predictions at threshold = 0.5\n",
    "threshold = 0.5\n",
    "y_pred = (y_forecast >= threshold).astype(int)\n",
    "\n",
    "# Compute metrics\n",
    "accuracy  = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall    = recall_score(y_true, y_pred)\n",
    "f1        = f1_score(y_true, y_pred)\n",
    "auc       = roc_auc_score(y_true, y_forecast)\n",
    "\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "print(f\"AUC      : {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4900f31-9cac-4ce8-af5f-a0548c886f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of transactions per wallet: 531.54\n"
     ]
    }
   ],
   "source": [
    "# Count transactions per wallet\n",
    "tx_counts = tx_df.groupby(\"address\").size()\n",
    "\n",
    "# Average transactions per wallet\n",
    "avg_tx = tx_counts.mean()\n",
    "\n",
    "print(f\"Average number of transactions per wallet: {avg_tx:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e41b9-7e6e-43b2-8c8e-63409c196c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
